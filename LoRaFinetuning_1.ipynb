{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "o28PTZGUfTyS",
      "metadata": {
        "id": "o28PTZGUfTyS"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade datasets -q\n",
        "# !pip install jiwer -q\n",
        "# !pip install evaluate -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04cc562d",
      "metadata": {
        "id": "04cc562d"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, DatasetDict\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "from torchaudio import load\n",
        "\n",
        "# Load Whisper processor\n",
        "from transformers import WhisperProcessor, WhisperFeatureExtractor, WhisperTokenizer\n",
        "from transformers import WhisperForConditionalGeneration\n",
        "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from huggingface_hub import login\n",
        "import os\n",
        "\n",
        "from dotenv import loa\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffea934c",
      "metadata": {
        "id": "ffea934c"
      },
      "outputs": [],
      "source": [
        "\n",
        "load_dotenv()\n",
        "login_token = os.getenv('HuggingFaceToken')\n",
        "\n",
        "login(login_token)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ce19b42",
      "metadata": {
        "id": "5ce19b42"
      },
      "source": [
        "## Data Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31731923",
      "metadata": {
        "id": "31731923"
      },
      "outputs": [],
      "source": [
        "common_voice = DatasetDict()\n",
        "\n",
        "common_voice[\"train\"] = load_dataset(\n",
        "    \"mozilla-foundation/common_voice_17_0\", \"ml\", split=\"train+validation\",\n",
        ")\n",
        "common_voice[\"test\"] = load_dataset(\n",
        "    \"mozilla-foundation/common_voice_17_0\", \"ml\", split=\"test\",\n",
        ")\n",
        "\n",
        "print(common_voice)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "788cad4a",
      "metadata": {
        "id": "788cad4a"
      },
      "outputs": [],
      "source": [
        "# remove unwanted features\n",
        "common_voice = common_voice.select_columns(['audio', 'sentence'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71afaaba",
      "metadata": {
        "id": "71afaaba"
      },
      "outputs": [],
      "source": [
        "print(common_voice['train'][0]['audio'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d5b848d",
      "metadata": {
        "id": "6d5b848d"
      },
      "outputs": [],
      "source": [
        "# 48kHz -> 16kHz\n",
        "from datasets import Audio\n",
        "common_voice = common_voice.cast_column(\"audio\", Audio(sampling_rate=16000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6c6b187",
      "metadata": {
        "id": "f6c6b187"
      },
      "outputs": [],
      "source": [
        "common_voice['train'][0]['audio']['array']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f35b2e7",
      "metadata": {
        "id": "9f35b2e7"
      },
      "outputs": [],
      "source": [
        "# def collate_fuc(batch):\n",
        "#     print(len(batch))\n",
        "#     print(batch[0].keys())\n",
        "# data_loader = DataLoader(common_voice['train'], batch_size=3, shuffle=True, collate_fn=collate_fuc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d45832d",
      "metadata": {
        "id": "1d45832d"
      },
      "outputs": [],
      "source": [
        "# for i in data_loader:\n",
        "#     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b55252f5",
      "metadata": {
        "id": "b55252f5"
      },
      "outputs": [],
      "source": [
        "# filtering audio len > 30 sec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a75ce08e",
      "metadata": {
        "id": "a75ce08e"
      },
      "outputs": [],
      "source": [
        "# whisper proccessor wrap whisperFeature extractor for audio and whispertokenizer for text labels as one processor\n",
        "feature_extractor = WhisperFeatureExtractor.from_pretrained('openai/whisper-small', task='transcribe', language='malayalam')\n",
        "tokenizer = WhisperTokenizer.from_pretrained('openai/whisper-small', task='transcribe', language='malayalam')\n",
        "processor = WhisperProcessor.from_pretrained('openai/whisper-small', task='transcribe', language='malayalam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6eea5ca5",
      "metadata": {
        "id": "6eea5ca5"
      },
      "outputs": [],
      "source": [
        "# sample_tokens = tokenizer.encode('ഇല്ല മോനേ')\n",
        "# tokenizer.decode(sample_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db6558f9",
      "metadata": {
        "id": "db6558f9"
      },
      "outputs": [],
      "source": [
        "text = 'ഇല്ല മോനേ'\n",
        "batch = processor(text=text, sampling_rate=16000)\n",
        "processor.tokenizer.decode(batch['input_ids'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a621160",
      "metadata": {
        "id": "7a621160"
      },
      "outputs": [],
      "source": [
        "# Prepare data\n",
        "def prepare_data(batch):\n",
        "    # processor have both feature extractor for audio and tokenizer for text, so we just pass both of theem\n",
        "    batch = processor(audio=batch['audio']['array'],\n",
        "                      text=batch['sentence'],\n",
        "                      sampling_rate=processor.feature_extractor.sampling_rate)\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_smrP8WQclQ8",
      "metadata": {
        "id": "_smrP8WQclQ8"
      },
      "outputs": [],
      "source": [
        "MAX_LABEL_TOKEN_WHISPER_SUPPORT = 448\n",
        "def filter_label_token(batch):\n",
        "    return len(batch['labels']) <= MAX_LABEL_TOKEN_WHISPER_SUPPORT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d9ce986",
      "metadata": {
        "id": "6d9ce986"
      },
      "outputs": [],
      "source": [
        "common_voice = common_voice.map(prepare_data, batched=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GocjjBKwdAP1",
      "metadata": {
        "id": "GocjjBKwdAP1"
      },
      "outputs": [],
      "source": [
        "common_voice = common_voice.filter(filter_label_token, batched=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb9dd23b",
      "metadata": {
        "id": "bb9dd23b"
      },
      "outputs": [],
      "source": [
        "common_voice = common_voice.select_columns(['input_features', 'labels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bYnUncrDhDBR",
      "metadata": {
        "id": "bYnUncrDhDBR"
      },
      "outputs": [],
      "source": [
        "common_voice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f734de1",
      "metadata": {
        "id": "7f734de1"
      },
      "outputs": [],
      "source": [
        "torch.tensor(common_voice['train'][0]['input_features']).shape # (1, 80, 3000)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "291e40c5",
      "metadata": {
        "id": "291e40c5"
      },
      "source": [
        "Dataloader takes random datapoints, here it will look like {input_feature:.., labels}, when batch enabled it will be like [{inp:.., lable:..}, {inp: .., label:..}], we need to use data collator for pad them and join them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f6badd5",
      "metadata": {
        "id": "3f6badd5"
      },
      "outputs": [],
      "source": [
        "# feature_extractor.pad(common_voice['train'][:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94f20449",
      "metadata": {
        "id": "94f20449"
      },
      "outputs": [],
      "source": [
        "len(common_voice['train'][0]['labels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b47615af",
      "metadata": {
        "id": "b47615af"
      },
      "outputs": [],
      "source": [
        "# Data Collator for padding\n",
        "\n",
        "class DataCollatorForSeqToSeqPadding:\n",
        "    def __init__(self, processor: WhisperProcessor):\n",
        "        self.processor = processor\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        # batch = [ {'input_feature':[], labels:[]}, {} ...]\n",
        "        input_features = [{\"input_features\" : data['input_features'][0]} for data in batch]\n",
        "        labels = [{\"input_ids\" : data['labels']} for data in batch]\n",
        "\n",
        "        # feature extractor from hugging face already support padding to {'input_features':[]}\n",
        "        # padding using feature extractor for audio and tokenizer for labels\n",
        "        batch = self.processor.feature_extractor.pad(input_features, return_tensors='pt') # created a batch object , later will add label to this too, that's how huggingface model expect data {'input_features':[], labels:[]}\n",
        "\n",
        "        # whisper tokenizer.pad will check the {'input_ids':[]} for padding and return in same forma\n",
        "        labels = self.processor.tokenizer.pad(labels, return_tensors='pt')\n",
        "\n",
        "\n",
        "        # since we are using hugging face model we don't need to stack the tensor cuz the hugging face (whisper here) model expect input like {'input_features':[], labels:[]}\n",
        "        # tensor stacking\n",
        "        # input_features = torch.stack(input_features, dim=0)\n",
        "        # labels = torch.stack(labels) # have\n",
        "\n",
        "\n",
        "        labels = labels['input_ids'].masked_fill(labels['attention_mask'].eq(0), -100)\n",
        "\n",
        "        # we are removing the start token since the hugging face model design to automatically add start token\n",
        "        # by doing shifting labels to right [1, 2, <\\s>] -> [<s>, 1, 2], where we using this shifted tensor as input\n",
        "        # and the non shifted as the labels to calculate the loss (the model gets what's his start token from the config)\n",
        "\n",
        "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
        "            print()\n",
        "            labels = labels[:, 1:]\n",
        "\n",
        "        batch[\"labels\"] = labels\n",
        "\n",
        "\n",
        "        return batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "261d2ff8",
      "metadata": {
        "id": "261d2ff8"
      },
      "outputs": [],
      "source": [
        "tokenizer.bos_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c849455e",
      "metadata": {
        "id": "c849455e"
      },
      "outputs": [],
      "source": [
        "tokenizer.decode(processor.tokenizer.bos_token_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "380221a8",
      "metadata": {
        "id": "380221a8"
      },
      "outputs": [],
      "source": [
        "collate_fn = DataCollatorForSeqToSeqPadding(processor=processor)\n",
        "\n",
        "# data loader for just checking the data collator, seqtoseq trainer does not need dataloader (inbuilt)\n",
        "data_loader = DataLoader(dataset=common_voice['train'],\n",
        "                         collate_fn=collate_fn,\n",
        "                         batch_size=2,\n",
        "                         shuffle=True,\n",
        "                         drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "daa93162",
      "metadata": {
        "id": "daa93162"
      },
      "outputs": [],
      "source": [
        "for batch in data_loader:\n",
        "    print(batch.keys()) # torch.Size([2, 80, 3000]), Yes now it's coming as batch size and not in (2, 1, 80, 3000)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf94029b",
      "metadata": {
        "id": "bf94029b"
      },
      "source": [
        "## Model setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd32e5a6",
      "metadata": {
        "id": "bd32e5a6"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "metric = evaluate.load('wer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5Fzcwve8jB7s",
      "metadata": {
        "id": "5Fzcwve8jB7s"
      },
      "outputs": [],
      "source": [
        "processor.tokenizer.pad_token_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "316f4a6b",
      "metadata": {
        "id": "316f4a6b"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(pred):\n",
        "    # pred will look like {'label_ids':[torch.tensor], prediction:[torch.tensor]}\n",
        "    pred_ids = pred.predictions\n",
        "    label_ids = pred.label_ids\n",
        "\n",
        "    # change all -100 value which we set for loss calculation back to padding since we are calculating wer\n",
        "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
        "\n",
        "    # convert to string and remove the padding token if there is.. if it was -100 then it won't work that is why we changed back to padding\n",
        "    pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
        "\n",
        "    # Now compute, the metric comes from the evaluate and we set it in the arugment of Trainer so compute metric use this metric here\n",
        "    wer = metric.compute(predictions=pred_str, references=label_str)\n",
        "\n",
        "    return {'wer': wer} # standard form of hugging face"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94f80821",
      "metadata": {
        "id": "94f80821"
      },
      "source": [
        "### Lora Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6aefe017",
      "metadata": {
        "id": "6aefe017"
      },
      "outputs": [],
      "source": [
        "from peft import LoraConfig, TaskType\n",
        "from peft import get_peft_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "798841f5",
      "metadata": {
        "id": "798841f5"
      },
      "outputs": [],
      "source": [
        "# Choose model size here\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
        "\n",
        "# forced decoder ids automatically add tokens at specified position (1, tokenizer.bos_token), so at decoder time the model automaticall generate it\n",
        "model.config.forced_decoder_ids = None\n",
        "model.config.suppress_tokens = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "460d1e91",
      "metadata": {
        "id": "460d1e91"
      },
      "outputs": [],
      "source": [
        "lora_r = 8\n",
        "lora_alpha = 16\n",
        "peft_config = LoraConfig(\n",
        "    r=lora_r,\n",
        "    lora_alpha=lora_alpha,\n",
        "    lora_dropout=0.05,\n",
        "    bias='none',\n",
        "    target_modules=['q_proj', 'v_proj', 'out_proj'],\n",
        "    task_type=None,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44V2F7zpVpCW",
      "metadata": {
        "id": "44V2F7zpVpCW"
      },
      "outputs": [],
      "source": [
        "model.config.use_cache = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08CX2DRqepbc",
      "metadata": {
        "id": "08CX2DRqepbc"
      },
      "outputs": [],
      "source": [
        "model.enable_input_require_grads()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24771f94",
      "metadata": {
        "id": "24771f94"
      },
      "outputs": [],
      "source": [
        "model = get_peft_model(model, peft_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "680728b2",
      "metadata": {
        "id": "680728b2"
      },
      "outputs": [],
      "source": [
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ec0c2af",
      "metadata": {
        "id": "8ec0c2af"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9MzW-Z2bZ8Up",
      "metadata": {
        "id": "9MzW-Z2bZ8Up"
      },
      "outputs": [],
      "source": [
        "# def compute_metrics(eval_pred):\n",
        "#     pred_ids, label_ids = eval_pred\n",
        "#     print(f\"pred_ids: {pred_ids}\")\n",
        "#     print(f\"label_ids: {label_ids}\")\n",
        "\n",
        "#     pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "#     label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n",
        "\n",
        "#     print(f\"pred_str: {pred_str}\")\n",
        "#     print(f\"label_str: {label_str}\")\n",
        "\n",
        "#     result = metric.compute(predictions=pred_str, references=label_str)\n",
        "#     return {'wer': result}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0_lzf95Ci96d",
      "metadata": {
        "id": "0_lzf95Ci96d"
      },
      "outputs": [],
      "source": [
        "# def compute_metrics(eval_pred):\n",
        "#     pred_ids, label_ids = eval_pred\n",
        "#     print(f\"pred_ids: {pred_ids}\")\n",
        "#     print(f\"label_ids: {label_ids}\")\n",
        "\n",
        "#     pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "#     label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n",
        "\n",
        "#     print(f\"pred_str: {pred_str}\")\n",
        "#     print(f\"label_str: {label_str}\")\n",
        "\n",
        "#     result = metric.compute(predictions=pred_str, references=label_str)\n",
        "#     return {'wer': result}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bd6dc1a",
      "metadata": {
        "id": "1bd6dc1a"
      },
      "outputs": [],
      "source": [
        "training_args = Seq2SeqTrainingArguments(output_dir='checkpoints',\n",
        "                                         eval_strategy='steps',\n",
        "                                         gradient_checkpointing=True,\n",
        "                                         per_device_train_batch_size=4,\n",
        "                                         gradient_accumulation_steps=4,\n",
        "                                         warmup_steps=50,\n",
        "                                         predict_with_generate=True,\n",
        "                                         per_device_eval_batch_size=1,\n",
        "                                         eval_accumulation_steps=2,\n",
        "                                         fp16=True,\n",
        "                                         save_steps=100,\n",
        "                                         eval_steps=10,\n",
        "                                         logging_dir=f'runs/{lora_r}_{lora_alpha}',\n",
        "                                         report_to=['tensorboard'],\n",
        "                                         load_best_model_at_end=True,\n",
        "                                         metric_for_best_model='wer',\n",
        "                                         num_train_epochs=2,\n",
        "                                         torch_empty_cache_steps=5,\n",
        "                                         dataloader_drop_last=True,\n",
        "                                        #  dataloader_num_workers=2,\n",
        "                                        #  dataloader_pin_memory=True,\n",
        "                                         logging_strategy='steps',\n",
        "                                         logging_steps=10,\n",
        "                                         optim='adamw_torch',\n",
        "                                         label_names=['labels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PITKfuOjquki",
      "metadata": {
        "id": "PITKfuOjquki"
      },
      "outputs": [],
      "source": [
        "metric.compute(predictions=['hello', 'world'], references=['hello', 'there'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76552312",
      "metadata": {
        "id": "76552312"
      },
      "outputs": [],
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    train_dataset=common_voice['train'],\n",
        "    eval_dataset=common_voice['test'],\n",
        "    args=training_args,\n",
        "    data_collator=DataCollatorForSeqToSeqPadding(processor=processor),\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cd5ed5f",
      "metadata": {
        "id": "0cd5ed5f"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8AVlqGqF4nK",
      "metadata": {
        "id": "a8AVlqGqF4nK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "M2nz_2zA_09Q",
      "metadata": {
        "id": "M2nz_2zA_09Q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Kie1Gbvj_07Q",
      "metadata": {
        "id": "Kie1Gbvj_07Q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oU31USsi_040",
      "metadata": {
        "id": "oU31USsi_040"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gDgOZepOjUhS",
      "metadata": {
        "id": "gDgOZepOjUhS"
      },
      "outputs": [],
      "source": [
        "def length_of_labels(batch):\n",
        "    return {\"label_len\" : len(batch['labels'])}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "A0W4iduw8S0l",
      "metadata": {
        "id": "A0W4iduw8S0l"
      },
      "outputs": [],
      "source": [
        "df = common_voice.map(length_of_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NnNK5g4-8lXB",
      "metadata": {
        "id": "NnNK5g4-8lXB"
      },
      "outputs": [],
      "source": [
        "train_label_length = df['train']['label_len']\n",
        "test_label_lenght = df['test']['label_len']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uTSn1yX08pMl",
      "metadata": {
        "id": "uTSn1yX08pMl"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9u6DSsX185Af",
      "metadata": {
        "id": "9u6DSsX185Af"
      },
      "outputs": [],
      "source": [
        "sns.distplot(test_label_lenght)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "J74KTRcm9RVX",
      "metadata": {
        "id": "J74KTRcm9RVX"
      },
      "outputs": [],
      "source": [
        "processor.tokenizer.pad([{'input_ids':df['train'][0]['labels']}])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pkuY34RJ87ru",
      "metadata": {
        "id": "pkuY34RJ87ru"
      },
      "outputs": [],
      "source": [
        "processor.tokenizer.pad()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
