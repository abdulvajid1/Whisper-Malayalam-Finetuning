{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "o28PTZGUfTyS",
      "metadata": {
        "id": "o28PTZGUfTyS"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade datasets -q\n",
        "# !pip install jiwer -q\n",
        "# !pip install evaluate -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "04cc562d",
      "metadata": {
        "id": "04cc562d"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, DatasetDict\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "from torchaudio import load\n",
        "import evaluate\n",
        "\n",
        "# Load Whisper processor\n",
        "from transformers import WhisperProcessor, WhisperFeatureExtractor, WhisperTokenizer\n",
        "from transformers import WhisperForConditionalGeneration\n",
        "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from huggingface_hub import login\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ffea934c",
      "metadata": {
        "id": "ffea934c"
      },
      "outputs": [],
      "source": [
        "\n",
        "load_dotenv()\n",
        "login_token = os.getenv('HuggingFaceToken')\n",
        "\n",
        "login(login_token)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ce19b42",
      "metadata": {
        "id": "5ce19b42"
      },
      "source": [
        "## Data Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "31731923",
      "metadata": {
        "id": "31731923"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'variant'],\n",
            "        num_rows: 2023\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'variant'],\n",
            "        num_rows: 710\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "common_voice = DatasetDict()\n",
        "\n",
        "common_voice[\"train\"] = load_dataset(\n",
        "    \"mozilla-foundation/common_voice_17_0\", \"ml\", split=\"train+validation\",\n",
        ")\n",
        "common_voice[\"test\"] = load_dataset(\n",
        "    \"mozilla-foundation/common_voice_17_0\", \"ml\", split=\"test\",\n",
        ")\n",
        "\n",
        "print(common_voice)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "788cad4a",
      "metadata": {
        "id": "788cad4a"
      },
      "outputs": [],
      "source": [
        "# remove unwanted features\n",
        "common_voice = common_voice.select_columns(['audio', 'sentence'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "71afaaba",
      "metadata": {
        "id": "71afaaba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'path': 'C:\\\\Users\\\\VICTUS\\\\.cache\\\\huggingface\\\\datasets\\\\downloads\\\\extracted\\\\3e7b12b0fa0deddeccc4a37a644801109d30fe7dda8b39a953688d0be0744a2f\\\\ml_train_0/common_voice_ml_37003897.mp3', 'array': array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
            "       1.33694380e-06, 6.72575652e-07, 1.44025307e-07], shape=(150336,)), 'sampling_rate': 48000}\n"
          ]
        }
      ],
      "source": [
        "print(common_voice['train'][0]['audio'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6d5b848d",
      "metadata": {
        "id": "6d5b848d"
      },
      "outputs": [],
      "source": [
        "# 48kHz -> 16kHz\n",
        "from datasets import Audio\n",
        "common_voice = common_voice.cast_column(\"audio\", Audio(sampling_rate=16000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f6c6b187",
      "metadata": {
        "id": "f6c6b187"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
              "       -1.61271237e-06, -1.26397367e-06,  1.32478658e-06], shape=(50112,))"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "common_voice['train'][0]['audio']['array']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9f35b2e7",
      "metadata": {
        "id": "9f35b2e7"
      },
      "outputs": [],
      "source": [
        "# def collate_fuc(batch):\n",
        "#     print(len(batch))\n",
        "#     print(batch[0].keys())\n",
        "# data_loader = DataLoader(common_voice['train'], batch_size=3, shuffle=True, collate_fn=collate_fuc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "1d45832d",
      "metadata": {
        "id": "1d45832d"
      },
      "outputs": [],
      "source": [
        "# for i in data_loader:\n",
        "#     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "b55252f5",
      "metadata": {
        "id": "b55252f5"
      },
      "outputs": [],
      "source": [
        "# filtering audio len > 30 sec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a75ce08e",
      "metadata": {
        "id": "a75ce08e"
      },
      "outputs": [],
      "source": [
        "# whisper proccessor wrap whisperFeature extractor for audio and whispertokenizer for text labels as one processor\n",
        "feature_extractor = WhisperFeatureExtractor.from_pretrained('openai/whisper-small', task='transcribe', language='malayalam')\n",
        "tokenizer = WhisperTokenizer.from_pretrained('openai/whisper-small', task='transcribe', language='malayalam')\n",
        "processor = WhisperProcessor.from_pretrained('openai/whisper-small', task='transcribe', language='malayalam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6eea5ca5",
      "metadata": {
        "id": "6eea5ca5"
      },
      "outputs": [],
      "source": [
        "# sample_tokens = tokenizer.encode('ഇല്ല മോനേ')\n",
        "# tokenizer.decode(sample_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "db6558f9",
      "metadata": {
        "id": "db6558f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'<|startoftranscript|><|ml|><|transcribe|><|notimestamps|>ഇല്ല മോനേ<|endoftext|>'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = 'ഇല്ല മോനേ'\n",
        "batch = processor(text=text, sampling_rate=16000)\n",
        "processor.tokenizer.decode(batch['input_ids'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "7a621160",
      "metadata": {
        "id": "7a621160"
      },
      "outputs": [],
      "source": [
        "# Prepare data\n",
        "def prepare_data(batch):\n",
        "    # processor have both feature extractor for audio and tokenizer for text, so we just pass both of theem\n",
        "    batch = processor(audio=batch['audio']['array'],\n",
        "                      text=batch['sentence'],\n",
        "                      sampling_rate=processor.feature_extractor.sampling_rate)\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "_smrP8WQclQ8",
      "metadata": {
        "id": "_smrP8WQclQ8"
      },
      "outputs": [],
      "source": [
        "MAX_LABEL_TOKEN_WHISPER_SUPPORT = 448\n",
        "def filter_label_token(batch):\n",
        "    return len(batch['labels']) <= MAX_LABEL_TOKEN_WHISPER_SUPPORT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "6d9ce986",
      "metadata": {
        "id": "6d9ce986"
      },
      "outputs": [],
      "source": [
        "common_voice = common_voice.map(prepare_data, batched=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "GocjjBKwdAP1",
      "metadata": {
        "id": "GocjjBKwdAP1"
      },
      "outputs": [],
      "source": [
        "common_voice = common_voice.filter(filter_label_token, batched=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "bb9dd23b",
      "metadata": {
        "id": "bb9dd23b"
      },
      "outputs": [],
      "source": [
        "common_voice = common_voice.select_columns(['input_features', 'labels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "bYnUncrDhDBR",
      "metadata": {
        "id": "bYnUncrDhDBR"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_features', 'labels'],\n",
              "        num_rows: 2022\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_features', 'labels'],\n",
              "        num_rows: 710\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "common_voice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "7f734de1",
      "metadata": {
        "id": "7f734de1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 80, 3000])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.tensor(common_voice['train'][0]['input_features']).shape # (1, 80, 3000)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "291e40c5",
      "metadata": {
        "id": "291e40c5"
      },
      "source": [
        "Dataloader takes random datapoints, here it will look like {input_feature:.., labels}, when batch enabled it will be like [{inp:.., lable:..}, {inp: .., label:..}], we need to use data collator for pad them and join them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "3f6badd5",
      "metadata": {
        "id": "3f6badd5"
      },
      "outputs": [],
      "source": [
        "# feature_extractor.pad(common_voice['train'][:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "94f20449",
      "metadata": {
        "id": "94f20449"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(common_voice['train'][0]['labels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "b47615af",
      "metadata": {
        "id": "b47615af"
      },
      "outputs": [],
      "source": [
        "# Data Collator for padding\n",
        "\n",
        "class DataCollatorForSeqToSeqPadding:\n",
        "    def __init__(self, processor: WhisperProcessor):\n",
        "        self.processor = processor\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        # batch = [ {'input_feature':[], labels:[]}, {} ...]\n",
        "        input_features = [{\"input_features\" : data['input_features'][0]} for data in batch]\n",
        "        labels = [{\"input_ids\" : data['labels']} for data in batch]\n",
        "\n",
        "        # feature extractor from hugging face already support padding to {'input_features':[]}\n",
        "        # padding using feature extractor for audio and tokenizer for labels\n",
        "        batch = self.processor.feature_extractor.pad(input_features, return_tensors='pt') # created a batch object , later will add label to this too, that's how huggingface model expect data {'input_features':[], labels:[]}\n",
        "\n",
        "        # whisper tokenizer.pad will check the {'input_ids':[]} for padding and return in same forma\n",
        "        labels = self.processor.tokenizer.pad(labels, return_tensors='pt')\n",
        "\n",
        "\n",
        "        # since we are using hugging face model we don't need to stack the tensor cuz the hugging face (whisper here) model expect input like {'input_features':[], labels:[]}\n",
        "        # tensor stacking\n",
        "        # input_features = torch.stack(input_features, dim=0)\n",
        "        # labels = torch.stack(labels) # have\n",
        "\n",
        "\n",
        "        labels = labels['input_ids'].masked_fill(labels['attention_mask'].eq(0), -100)\n",
        "\n",
        "        # we are removing the start token since the hugging face model design to automatically add start token\n",
        "        # by doing shifting labels to right [1, 2, <\\s>] -> [<s>, 1, 2], where we using this shifted tensor as input\n",
        "        # and the non shifted as the labels to calculate the loss (the model gets what's his start token from the config)\n",
        "\n",
        "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
        "            print()\n",
        "            labels = labels[:, 1:]\n",
        "\n",
        "        batch[\"labels\"] = labels\n",
        "\n",
        "\n",
        "        return batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "261d2ff8",
      "metadata": {
        "id": "261d2ff8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50257"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.bos_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "c849455e",
      "metadata": {
        "id": "c849455e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'<|endoftext|>'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.decode(processor.tokenizer.bos_token_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "380221a8",
      "metadata": {
        "id": "380221a8"
      },
      "outputs": [],
      "source": [
        "collate_fn = DataCollatorForSeqToSeqPadding(processor=processor)\n",
        "\n",
        "# data loader for just checking the data collator, seqtoseq trainer does not need dataloader (inbuilt)\n",
        "data_loader = DataLoader(dataset=common_voice['train'],\n",
        "                         collate_fn=collate_fn,\n",
        "                         batch_size=2,\n",
        "                         shuffle=True,\n",
        "                         drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "daa93162",
      "metadata": {
        "id": "daa93162"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['input_features', 'labels'])\n"
          ]
        }
      ],
      "source": [
        "for batch in data_loader:\n",
        "    print(batch.keys()) # torch.Size([2, 80, 3000]), Yes now it's coming as batch size and not in (2, 1, 80, 3000)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf94029b",
      "metadata": {
        "id": "bf94029b"
      },
      "source": [
        "## Model setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "bd32e5a6",
      "metadata": {
        "id": "bd32e5a6"
      },
      "outputs": [],
      "source": [
        "metric = evaluate.load('wer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "5Fzcwve8jB7s",
      "metadata": {
        "id": "5Fzcwve8jB7s"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50257"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processor.tokenizer.pad_token_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "316f4a6b",
      "metadata": {
        "id": "316f4a6b"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(pred):\n",
        "    # pred will look like {'label_ids':[torch.tensor], prediction:[torch.tensor]}\n",
        "    pred_ids = pred.predictions\n",
        "    label_ids = pred.label_ids\n",
        "\n",
        "    # change all -100 value which we set for loss calculation back to padding since we are calculating wer\n",
        "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
        "\n",
        "    # convert to string and remove the padding token if there is.. if it was -100 then it won't work that is why we changed back to padding\n",
        "    pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
        "\n",
        "    # Now compute, the metric comes from the evaluate and we set it in the arugment of Trainer so compute metric use this metric here\n",
        "    wer = metric.compute(predictions=pred_str, references=label_str)\n",
        "\n",
        "    return {'wer': wer} # standard form of hugging face"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94f80821",
      "metadata": {
        "id": "94f80821"
      },
      "source": [
        "### Lora Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "6aefe017",
      "metadata": {
        "id": "6aefe017"
      },
      "outputs": [],
      "source": [
        "from peft import LoraConfig, TaskType\n",
        "from peft import get_peft_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "798841f5",
      "metadata": {
        "id": "798841f5"
      },
      "outputs": [],
      "source": [
        "# Choose model size here\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
        "\n",
        "# forced decoder ids automatically add tokens at specified position (1, tokenizer.bos_token), so at decoder time the model automaticall generate it\n",
        "model.config.forced_decoder_ids = None\n",
        "model.config.suppress_tokens = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "460d1e91",
      "metadata": {
        "id": "460d1e91"
      },
      "outputs": [],
      "source": [
        "lora_r = 8\n",
        "lora_alpha = 16\n",
        "learning_rate = 1e-5\n",
        "peft_config = LoraConfig(\n",
        "    r=lora_r,\n",
        "    lora_alpha=lora_alpha,\n",
        "    lora_dropout=0.05,\n",
        "    bias='none',\n",
        "    target_modules=['q_proj', 'v_proj', 'out_proj'],\n",
        "    task_type=None,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "44V2F7zpVpCW",
      "metadata": {
        "id": "44V2F7zpVpCW"
      },
      "outputs": [],
      "source": [
        "model.config.use_cache = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "08CX2DRqepbc",
      "metadata": {
        "id": "08CX2DRqepbc"
      },
      "outputs": [],
      "source": [
        "model.enable_input_require_grads()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "24771f94",
      "metadata": {
        "id": "24771f94"
      },
      "outputs": [],
      "source": [
        "model = get_peft_model(model, peft_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "680728b2",
      "metadata": {
        "id": "680728b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 1,327,104 || all params: 243,062,016 || trainable%: 0.5460\n"
          ]
        }
      ],
      "source": [
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "8ec0c2af",
      "metadata": {
        "id": "8ec0c2af"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "02c90f7b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0001"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "1e-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bd6dc1a",
      "metadata": {
        "id": "1bd6dc1a"
      },
      "outputs": [],
      "source": [
        "training_args = Seq2SeqTrainingArguments(output_dir='checkpoints',\n",
        "                                         eval_strategy='steps',\n",
        "                                         learning_rate=learning_rate,\n",
        "                                         gradient_checkpointing=True,\n",
        "                                         per_device_train_batch_size=4,\n",
        "                                         gradient_accumulation_steps=4,\n",
        "                                         warmup_steps=50,\n",
        "                                         predict_with_generate=True,\n",
        "                                         generation_max_length=30,\n",
        "                                         per_device_eval_batch_size=1,\n",
        "                                         eval_accumulation_steps=2,\n",
        "                                         fp16=True,\n",
        "                                         save_steps=100,\n",
        "                                         eval_steps=10,\n",
        "                                         logging_dir=f'runs/{lora_r}_{lora_alpha}_{learning_rate}',\n",
        "                                         report_to=['tensorboard'],\n",
        "                                         load_best_model_at_end=True,\n",
        "                                         metric_for_best_model='wer',\n",
        "                                         num_train_epochs=2,\n",
        "                                         torch_empty_cache_steps=5,\n",
        "                                         dataloader_drop_last=True,\n",
        "                                        #  dataloader_num_workers=2,\n",
        "                                        #  dataloader_pin_memory=True,\n",
        "                                         logging_strategy='steps',\n",
        "                                         logging_steps=10,\n",
        "                                         optim='adamw_torch',\n",
        "                                         label_names=['labels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "PITKfuOjquki",
      "metadata": {
        "id": "PITKfuOjquki"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metric.compute(predictions=['hello', 'world'], references=['hello', 'there'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "76552312",
      "metadata": {
        "id": "76552312"
      },
      "outputs": [],
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    train_dataset=common_voice['train'],\n",
        "    eval_dataset=common_voice['test'].shuffle(seed=0).select(range(20)),\n",
        "    args=training_args,\n",
        "    data_collator=DataCollatorForSeqToSeqPadding(processor=processor),\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "2d16436d",
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "0cd5ed5f",
      "metadata": {
        "id": "0cd5ed5f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Machine Learning\\INTERNSHIP\\Whisper-Malayalam-Finetuning\\.venv\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='253' max='254' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [253/254 04:31 < 00:05, 0.19 it/s, Epoch 1/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Wer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>1.354600</td>\n",
              "      <td>1.456796</td>\n",
              "      <td>1.048193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>1.366200</td>\n",
              "      <td>1.453211</td>\n",
              "      <td>1.048193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>1.346900</td>\n",
              "      <td>1.450304</td>\n",
              "      <td>1.048193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>1.348600</td>\n",
              "      <td>1.447684</td>\n",
              "      <td>1.048193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.331600</td>\n",
              "      <td>1.446110</td>\n",
              "      <td>1.048193</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=253, training_loss=0.28412104406846844, metrics={'train_runtime': 275.1473, 'train_samples_per_second': 14.698, 'train_steps_per_second': 0.923, 'total_flos': 1.18754940616704e+18, 'train_loss': 0.28412104406846844, 'epoch': 1.998019801980198})"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train(resume_from_checkpoint='checkpoints\\\\checkpoint-200')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Kie1Gbvj_07Q",
      "metadata": {
        "id": "Kie1Gbvj_07Q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oU31USsi_040",
      "metadata": {
        "id": "oU31USsi_040"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gDgOZepOjUhS",
      "metadata": {
        "id": "gDgOZepOjUhS"
      },
      "outputs": [],
      "source": [
        "def length_of_labels(batch):\n",
        "    return {\"label_len\" : len(batch['labels'])}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "A0W4iduw8S0l",
      "metadata": {
        "id": "A0W4iduw8S0l"
      },
      "outputs": [],
      "source": [
        "df = common_voice.map(length_of_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NnNK5g4-8lXB",
      "metadata": {
        "id": "NnNK5g4-8lXB"
      },
      "outputs": [],
      "source": [
        "train_label_length = df['train']['label_len']\n",
        "test_label_lenght = df['test']['label_len']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uTSn1yX08pMl",
      "metadata": {
        "id": "uTSn1yX08pMl"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9u6DSsX185Af",
      "metadata": {
        "id": "9u6DSsX185Af"
      },
      "outputs": [],
      "source": [
        "sns.distplot(test_label_lenght)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "J74KTRcm9RVX",
      "metadata": {
        "id": "J74KTRcm9RVX"
      },
      "outputs": [],
      "source": [
        "processor.tokenizer.pad([{'input_ids':df['train'][0]['labels']}])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pkuY34RJ87ru",
      "metadata": {
        "id": "pkuY34RJ87ru"
      },
      "outputs": [],
      "source": [
        "processor.tokenizer.pad()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
