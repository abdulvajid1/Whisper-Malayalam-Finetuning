{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "o28PTZGUfTyS",
      "metadata": {
        "id": "o28PTZGUfTyS"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade datasets -q\n",
        "# !pip install jiwer -q\n",
        "# !pip install evaluate -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "04cc562d",
      "metadata": {
        "id": "04cc562d"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, DatasetDict\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "from torchaudio import load\n",
        "import evaluate\n",
        "\n",
        "# Load Whisper processor\n",
        "from transformers import WhisperProcessor, WhisperFeatureExtractor, WhisperTokenizer\n",
        "from transformers import WhisperForConditionalGeneration\n",
        "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from huggingface_hub import login\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ffea934c",
      "metadata": {
        "id": "ffea934c"
      },
      "outputs": [],
      "source": [
        "\n",
        "load_dotenv()\n",
        "login_token = os.getenv('HuggingFaceToken')\n",
        "\n",
        "login(login_token)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ce19b42",
      "metadata": {
        "id": "5ce19b42"
      },
      "source": [
        "## Data Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "31731923",
      "metadata": {
        "id": "31731923"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'variant'],\n",
            "        num_rows: 2023\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'variant'],\n",
            "        num_rows: 710\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "common_voice = DatasetDict()\n",
        "\n",
        "common_voice[\"train\"] = load_dataset(\n",
        "    \"mozilla-foundation/common_voice_17_0\", \"ml\", split=\"train+validation\",\n",
        ")\n",
        "common_voice[\"test\"] = load_dataset(\n",
        "    \"mozilla-foundation/common_voice_17_0\", \"ml\", split=\"test\",\n",
        ")\n",
        "\n",
        "print(common_voice)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "788cad4a",
      "metadata": {
        "id": "788cad4a"
      },
      "outputs": [],
      "source": [
        "# remove unwanted features\n",
        "common_voice = common_voice.select_columns(['audio', 'sentence'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "71afaaba",
      "metadata": {
        "id": "71afaaba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'path': 'C:\\\\Users\\\\VICTUS\\\\.cache\\\\huggingface\\\\datasets\\\\downloads\\\\extracted\\\\3e7b12b0fa0deddeccc4a37a644801109d30fe7dda8b39a953688d0be0744a2f\\\\ml_train_0/common_voice_ml_37003897.mp3', 'array': array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
            "       1.33694380e-06, 6.72575652e-07, 1.44025307e-07], shape=(150336,)), 'sampling_rate': 48000}\n"
          ]
        }
      ],
      "source": [
        "print(common_voice['train'][0]['audio'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6d5b848d",
      "metadata": {
        "id": "6d5b848d"
      },
      "outputs": [],
      "source": [
        "# 48kHz -> 16kHz\n",
        "from datasets import Audio\n",
        "common_voice = common_voice.cast_column(\"audio\", Audio(sampling_rate=16000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f6c6b187",
      "metadata": {
        "id": "f6c6b187"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
              "       -1.61271237e-06, -1.26397367e-06,  1.32478658e-06], shape=(50112,))"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "common_voice['train'][0]['audio']['array']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9f35b2e7",
      "metadata": {
        "id": "9f35b2e7"
      },
      "outputs": [],
      "source": [
        "# def collate_fuc(batch):\n",
        "#     print(len(batch))\n",
        "#     print(batch[0].keys())\n",
        "# data_loader = DataLoader(common_voice['train'], batch_size=3, shuffle=True, collate_fn=collate_fuc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "1d45832d",
      "metadata": {
        "id": "1d45832d"
      },
      "outputs": [],
      "source": [
        "# for i in data_loader:\n",
        "#     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "b55252f5",
      "metadata": {
        "id": "b55252f5"
      },
      "outputs": [],
      "source": [
        "# filtering audio len > 30 sec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a75ce08e",
      "metadata": {
        "id": "a75ce08e"
      },
      "outputs": [],
      "source": [
        "# whisper proccessor wrap whisperFeature extractor for audio and whispertokenizer for text labels as one processor\n",
        "feature_extractor = WhisperFeatureExtractor.from_pretrained('openai/whisper-small', task='transcribe', language='malayalam')\n",
        "tokenizer = WhisperTokenizer.from_pretrained('openai/whisper-small', task='transcribe', language='malayalam')\n",
        "processor = WhisperProcessor.from_pretrained('openai/whisper-small', task='transcribe', language='malayalam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6eea5ca5",
      "metadata": {
        "id": "6eea5ca5"
      },
      "outputs": [],
      "source": [
        "# sample_tokens = tokenizer.encode('ഇല്ല മോനേ')\n",
        "# tokenizer.decode(sample_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "db6558f9",
      "metadata": {
        "id": "db6558f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'<|startoftranscript|><|ml|><|transcribe|><|notimestamps|>ഇല്ല മോനേ<|endoftext|>'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = 'ഇല്ല മോനേ'\n",
        "batch = processor(text=text, sampling_rate=16000)\n",
        "processor.tokenizer.decode(batch['input_ids'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "7a621160",
      "metadata": {
        "id": "7a621160"
      },
      "outputs": [],
      "source": [
        "# Prepare data\n",
        "def prepare_data(batch):\n",
        "    # processor have both feature extractor for audio and tokenizer for text, so we just pass both of theem\n",
        "    batch = processor(audio=batch['audio']['array'],\n",
        "                      text=batch['sentence'],\n",
        "                      sampling_rate=processor.feature_extractor.sampling_rate)\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "_smrP8WQclQ8",
      "metadata": {
        "id": "_smrP8WQclQ8"
      },
      "outputs": [],
      "source": [
        "MAX_LABEL_TOKEN_WHISPER_SUPPORT = 448\n",
        "def filter_label_token(batch):\n",
        "    return len(batch['labels']) <= MAX_LABEL_TOKEN_WHISPER_SUPPORT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "6d9ce986",
      "metadata": {
        "id": "6d9ce986"
      },
      "outputs": [],
      "source": [
        "common_voice = common_voice.map(prepare_data, batched=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "GocjjBKwdAP1",
      "metadata": {
        "id": "GocjjBKwdAP1"
      },
      "outputs": [],
      "source": [
        "common_voice = common_voice.filter(filter_label_token, batched=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "bb9dd23b",
      "metadata": {
        "id": "bb9dd23b"
      },
      "outputs": [],
      "source": [
        "common_voice = common_voice.select_columns(['input_features', 'labels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "bYnUncrDhDBR",
      "metadata": {
        "id": "bYnUncrDhDBR"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_features', 'labels'],\n",
              "        num_rows: 2022\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_features', 'labels'],\n",
              "        num_rows: 710\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "common_voice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "7f734de1",
      "metadata": {
        "id": "7f734de1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 80, 3000])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.tensor(common_voice['train'][0]['input_features']).shape # (1, 80, 3000)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "291e40c5",
      "metadata": {
        "id": "291e40c5"
      },
      "source": [
        "Dataloader takes random datapoints, here it will look like {input_feature:.., labels}, when batch enabled it will be like [{inp:.., lable:..}, {inp: .., label:..}], we need to use data collator for pad them and join them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "3f6badd5",
      "metadata": {
        "id": "3f6badd5"
      },
      "outputs": [],
      "source": [
        "# feature_extractor.pad(common_voice['train'][:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "94f20449",
      "metadata": {
        "id": "94f20449"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(common_voice['train'][0]['labels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "b47615af",
      "metadata": {
        "id": "b47615af"
      },
      "outputs": [],
      "source": [
        "# Data Collator for padding\n",
        "\n",
        "class DataCollatorForSeqToSeqPadding:\n",
        "    def __init__(self, processor: WhisperProcessor):\n",
        "        self.processor = processor\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        # batch = [ {'input_feature':[], labels:[]}, {} ...]\n",
        "        input_features = [{\"input_features\" : data['input_features'][0]} for data in batch]\n",
        "        labels = [{\"input_ids\" : data['labels']} for data in batch]\n",
        "\n",
        "        # feature extractor from hugging face already support padding to {'input_features':[]}\n",
        "        # padding using feature extractor for audio and tokenizer for labels\n",
        "        batch = self.processor.feature_extractor.pad(input_features, return_tensors='pt') # created a batch object , later will add label to this too, that's how huggingface model expect data {'input_features':[], labels:[]}\n",
        "\n",
        "        # whisper tokenizer.pad will check the {'input_ids':[]} for padding and return in same forma\n",
        "        labels = self.processor.tokenizer.pad(labels, return_tensors='pt')\n",
        "\n",
        "\n",
        "        # since we are using hugging face model we don't need to stack the tensor cuz the hugging face (whisper here) model expect input like {'input_features':[], labels:[]}\n",
        "        # tensor stacking\n",
        "        # input_features = torch.stack(input_features, dim=0)\n",
        "        # labels = torch.stack(labels) # have\n",
        "\n",
        "\n",
        "        labels = labels['input_ids'].masked_fill(labels['attention_mask'].eq(0), -100)\n",
        "\n",
        "        # we are removing the start token since the hugging face model design to automatically add start token\n",
        "        # by doing shifting labels to right [1, 2, <\\s>] -> [<s>, 1, 2], where we using this shifted tensor as input\n",
        "        # and the non shifted as the labels to calculate the loss (the model gets what's his start token from the config)\n",
        "\n",
        "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
        "            print()\n",
        "            labels = labels[:, 1:]\n",
        "\n",
        "        batch[\"labels\"] = labels\n",
        "\n",
        "\n",
        "        return batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "261d2ff8",
      "metadata": {
        "id": "261d2ff8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50257"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.bos_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "c849455e",
      "metadata": {
        "id": "c849455e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'<|endoftext|>'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.decode(processor.tokenizer.bos_token_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "380221a8",
      "metadata": {
        "id": "380221a8"
      },
      "outputs": [],
      "source": [
        "collate_fn = DataCollatorForSeqToSeqPadding(processor=processor)\n",
        "\n",
        "# data loader for just checking the data collator, seqtoseq trainer does not need dataloader (inbuilt)\n",
        "data_loader = DataLoader(dataset=common_voice['train'],\n",
        "                         collate_fn=collate_fn,\n",
        "                         batch_size=2,\n",
        "                         shuffle=True,\n",
        "                         drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "daa93162",
      "metadata": {
        "id": "daa93162"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['input_features', 'labels'])\n"
          ]
        }
      ],
      "source": [
        "for batch in data_loader:\n",
        "    print(batch.keys()) # torch.Size([2, 80, 3000]), Yes now it's coming as batch size and not in (2, 1, 80, 3000)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf94029b",
      "metadata": {
        "id": "bf94029b"
      },
      "source": [
        "## Model setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "bd32e5a6",
      "metadata": {
        "id": "bd32e5a6"
      },
      "outputs": [],
      "source": [
        "metric = evaluate.load('wer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "5Fzcwve8jB7s",
      "metadata": {
        "id": "5Fzcwve8jB7s"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50257"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processor.tokenizer.pad_token_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "316f4a6b",
      "metadata": {
        "id": "316f4a6b"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(pred):\n",
        "    # pred will look like {'label_ids':[torch.tensor], prediction:[torch.tensor]}\n",
        "    pred_ids = pred.predictions\n",
        "    label_ids = pred.label_ids\n",
        "\n",
        "    # change all -100 value which we set for loss calculation back to padding since we are calculating wer\n",
        "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
        "\n",
        "    # convert to string and remove the padding token if there is.. if it was -100 then it won't work that is why we changed back to padding\n",
        "    pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
        "\n",
        "    # Now compute, the metric comes from the evaluate and we set it in the arugment of Trainer so compute metric use this metric here\n",
        "    wer = metric.compute(predictions=pred_str, references=label_str)\n",
        "\n",
        "    return {'wer': wer} # standard form of hugging face"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94f80821",
      "metadata": {
        "id": "94f80821"
      },
      "source": [
        "### Lora Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "6aefe017",
      "metadata": {
        "id": "6aefe017"
      },
      "outputs": [],
      "source": [
        "from peft import LoraConfig, TaskType\n",
        "from peft import get_peft_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "798841f5",
      "metadata": {
        "id": "798841f5"
      },
      "outputs": [],
      "source": [
        "# Choose model size here\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
        "\n",
        "# forced decoder ids automatically add tokens at specified position (1, tokenizer.bos_token), so at decoder time the model automaticall generate it\n",
        "model.config.forced_decoder_ids = None\n",
        "model.config.suppress_tokens = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "460d1e91",
      "metadata": {
        "id": "460d1e91"
      },
      "outputs": [],
      "source": [
        "lora_r = 64\n",
        "lora_alpha = 128\n",
        "learning_rate = 5e-5\n",
        "peft_config = LoraConfig(\n",
        "    r=lora_r,\n",
        "    lora_alpha=lora_alpha,\n",
        "    lora_dropout=0.001,\n",
        "    bias='none',\n",
        "    target_modules=['q_proj', 'v_proj', 'out_proj'],\n",
        "    task_type=None,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "44V2F7zpVpCW",
      "metadata": {
        "id": "44V2F7zpVpCW"
      },
      "outputs": [],
      "source": [
        "model.config.use_cache = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "08CX2DRqepbc",
      "metadata": {
        "id": "08CX2DRqepbc"
      },
      "outputs": [],
      "source": [
        "model.enable_input_require_grads()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "24771f94",
      "metadata": {
        "id": "24771f94"
      },
      "outputs": [],
      "source": [
        "model = get_peft_model(model, peft_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "680728b2",
      "metadata": {
        "id": "680728b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 10,616,832 || all params: 252,351,744 || trainable%: 4.2072\n"
          ]
        }
      ],
      "source": [
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "8ec0c2af",
      "metadata": {
        "id": "8ec0c2af"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "1bd6dc1a",
      "metadata": {
        "id": "1bd6dc1a"
      },
      "outputs": [],
      "source": [
        "training_args = Seq2SeqTrainingArguments(output_dir='checkpoints',\n",
        "                                         eval_strategy='steps',\n",
        "                                         learning_rate=learning_rate,\n",
        "                                         gradient_checkpointing=True,\n",
        "                                         per_device_train_batch_size=4,\n",
        "                                         gradient_accumulation_steps=2,\n",
        "                                         warmup_steps=50,\n",
        "                                         predict_with_generate=True,\n",
        "                                         generation_max_length=30,\n",
        "                                         per_device_eval_batch_size=1,\n",
        "                                        #  eval_accumulation_steps=2,\n",
        "                                         fp16=True,\n",
        "                                         save_steps=100,\n",
        "                                         eval_steps=10,\n",
        "                                         logging_dir=f'runs/{lora_r}_{lora_alpha}_{learning_rate}',\n",
        "                                         report_to=['tensorboard'],\n",
        "                                         load_best_model_at_end=True,\n",
        "                                         metric_for_best_model='wer',\n",
        "                                         num_train_epochs=5,\n",
        "                                         torch_empty_cache_steps=5,\n",
        "                                         dataloader_drop_last=True,\n",
        "                                        #  dataloader_num_workers=2,\n",
        "                                        #  dataloader_pin_memory=True,\n",
        "                                         logging_strategy='steps',\n",
        "                                         logging_steps=10,\n",
        "                                         optim='adamw_torch',\n",
        "                                         label_names=['labels'],\n",
        "                                         lr_scheduler_type=\"constant\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "PITKfuOjquki",
      "metadata": {
        "id": "PITKfuOjquki"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metric.compute(predictions=['hello', 'world'], references=['hello', 'there'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "76552312",
      "metadata": {
        "id": "76552312"
      },
      "outputs": [],
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    train_dataset=common_voice['train'],\n",
        "    eval_dataset=common_voice['test'].shuffle(seed=0).select(range(20)),\n",
        "    args=training_args,\n",
        "    data_collator=DataCollatorForSeqToSeqPadding(processor=processor),\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "2d16436d",
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "0cd5ed5f",
      "metadata": {
        "id": "0cd5ed5f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Machine Learning\\INTERNSHIP\\Whisper-Malayalam-Finetuning\\.venv\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1265' max='1265' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1265/1265 1:16:29, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Wer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.214900</td>\n",
              "      <td>2.219674</td>\n",
              "      <td>1.072289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.799900</td>\n",
              "      <td>1.864342</td>\n",
              "      <td>1.060241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.574200</td>\n",
              "      <td>1.598563</td>\n",
              "      <td>1.060241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.453000</td>\n",
              "      <td>1.530585</td>\n",
              "      <td>1.024096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.384900</td>\n",
              "      <td>1.467879</td>\n",
              "      <td>1.024096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.325900</td>\n",
              "      <td>1.412217</td>\n",
              "      <td>1.024096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.283800</td>\n",
              "      <td>1.374228</td>\n",
              "      <td>1.024096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.256700</td>\n",
              "      <td>1.325157</td>\n",
              "      <td>1.024096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.234200</td>\n",
              "      <td>1.281287</td>\n",
              "      <td>1.024096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.223500</td>\n",
              "      <td>1.246882</td>\n",
              "      <td>1.024096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>1.128900</td>\n",
              "      <td>1.207151</td>\n",
              "      <td>1.024096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.149900</td>\n",
              "      <td>1.163853</td>\n",
              "      <td>1.024096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>1.068400</td>\n",
              "      <td>1.150682</td>\n",
              "      <td>1.024096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>1.018200</td>\n",
              "      <td>1.089479</td>\n",
              "      <td>1.012048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.013900</td>\n",
              "      <td>1.060450</td>\n",
              "      <td>1.012048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>1.015686</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.941800</td>\n",
              "      <td>0.991116</td>\n",
              "      <td>1.024096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.905500</td>\n",
              "      <td>0.930929</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.904400</td>\n",
              "      <td>0.924598</td>\n",
              "      <td>1.024096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.860400</td>\n",
              "      <td>0.891808</td>\n",
              "      <td>1.012048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.819300</td>\n",
              "      <td>0.857644</td>\n",
              "      <td>0.975904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.800200</td>\n",
              "      <td>0.830728</td>\n",
              "      <td>0.987952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.783100</td>\n",
              "      <td>0.791074</td>\n",
              "      <td>0.987952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.735700</td>\n",
              "      <td>0.763315</td>\n",
              "      <td>0.975904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.716300</td>\n",
              "      <td>0.756007</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.672500</td>\n",
              "      <td>0.693528</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.624300</td>\n",
              "      <td>0.644949</td>\n",
              "      <td>1.048193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.566800</td>\n",
              "      <td>0.520255</td>\n",
              "      <td>1.036145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.494900</td>\n",
              "      <td>0.454732</td>\n",
              "      <td>1.036145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.517000</td>\n",
              "      <td>0.473384</td>\n",
              "      <td>1.060241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.493100</td>\n",
              "      <td>0.434696</td>\n",
              "      <td>1.096386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.451900</td>\n",
              "      <td>0.412400</td>\n",
              "      <td>1.072289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>0.439100</td>\n",
              "      <td>0.421631</td>\n",
              "      <td>1.144578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.471000</td>\n",
              "      <td>0.403869</td>\n",
              "      <td>1.060241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.407500</td>\n",
              "      <td>0.391412</td>\n",
              "      <td>1.036145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.457800</td>\n",
              "      <td>0.395641</td>\n",
              "      <td>1.036145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>0.425500</td>\n",
              "      <td>0.371752</td>\n",
              "      <td>1.024096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.398000</td>\n",
              "      <td>0.368248</td>\n",
              "      <td>1.084337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>0.428700</td>\n",
              "      <td>0.363304</td>\n",
              "      <td>1.072289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.393500</td>\n",
              "      <td>0.361818</td>\n",
              "      <td>1.084337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>0.398000</td>\n",
              "      <td>0.344834</td>\n",
              "      <td>1.036145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.377400</td>\n",
              "      <td>0.346816</td>\n",
              "      <td>1.048193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>0.417900</td>\n",
              "      <td>0.352526</td>\n",
              "      <td>1.024096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.380700</td>\n",
              "      <td>0.327895</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.358600</td>\n",
              "      <td>0.338597</td>\n",
              "      <td>0.987952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.358600</td>\n",
              "      <td>0.331709</td>\n",
              "      <td>0.975904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>0.353700</td>\n",
              "      <td>0.339950</td>\n",
              "      <td>0.987952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.352200</td>\n",
              "      <td>0.325485</td>\n",
              "      <td>1.024096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>0.377100</td>\n",
              "      <td>0.317132</td>\n",
              "      <td>0.963855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.344200</td>\n",
              "      <td>0.306395</td>\n",
              "      <td>1.012048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>0.349000</td>\n",
              "      <td>0.313086</td>\n",
              "      <td>1.024096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>0.342200</td>\n",
              "      <td>0.307477</td>\n",
              "      <td>1.096386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>0.311400</td>\n",
              "      <td>0.303099</td>\n",
              "      <td>1.012048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>0.338900</td>\n",
              "      <td>0.318151</td>\n",
              "      <td>1.084337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.305800</td>\n",
              "      <td>0.330433</td>\n",
              "      <td>1.036145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>0.299300</td>\n",
              "      <td>0.312425</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>0.311600</td>\n",
              "      <td>0.300474</td>\n",
              "      <td>0.951807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>0.294100</td>\n",
              "      <td>0.301035</td>\n",
              "      <td>1.024096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>0.273300</td>\n",
              "      <td>0.294378</td>\n",
              "      <td>0.951807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.279100</td>\n",
              "      <td>0.286348</td>\n",
              "      <td>0.963855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>610</td>\n",
              "      <td>0.315400</td>\n",
              "      <td>0.283042</td>\n",
              "      <td>0.951807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>0.289100</td>\n",
              "      <td>0.293630</td>\n",
              "      <td>0.975904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>630</td>\n",
              "      <td>0.266200</td>\n",
              "      <td>0.286583</td>\n",
              "      <td>0.987952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>0.273800</td>\n",
              "      <td>0.290086</td>\n",
              "      <td>0.939759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.298700</td>\n",
              "      <td>0.282725</td>\n",
              "      <td>0.939759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>0.245400</td>\n",
              "      <td>0.271755</td>\n",
              "      <td>0.975904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>670</td>\n",
              "      <td>0.285800</td>\n",
              "      <td>0.277792</td>\n",
              "      <td>0.963855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>0.293500</td>\n",
              "      <td>0.286794</td>\n",
              "      <td>0.987952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>0.297400</td>\n",
              "      <td>0.281993</td>\n",
              "      <td>0.975904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.271900</td>\n",
              "      <td>0.261290</td>\n",
              "      <td>0.963855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>710</td>\n",
              "      <td>0.235100</td>\n",
              "      <td>0.253139</td>\n",
              "      <td>1.024096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>0.263300</td>\n",
              "      <td>0.301940</td>\n",
              "      <td>0.987952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>730</td>\n",
              "      <td>0.285600</td>\n",
              "      <td>0.278063</td>\n",
              "      <td>0.987952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>0.290900</td>\n",
              "      <td>0.264978</td>\n",
              "      <td>1.084337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.277000</td>\n",
              "      <td>0.258904</td>\n",
              "      <td>0.951807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>0.233400</td>\n",
              "      <td>0.263436</td>\n",
              "      <td>0.939759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>770</td>\n",
              "      <td>0.254900</td>\n",
              "      <td>0.257711</td>\n",
              "      <td>0.915663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>0.234000</td>\n",
              "      <td>0.252406</td>\n",
              "      <td>0.951807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>790</td>\n",
              "      <td>0.237800</td>\n",
              "      <td>0.269362</td>\n",
              "      <td>0.915663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.216600</td>\n",
              "      <td>0.275429</td>\n",
              "      <td>0.939759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>810</td>\n",
              "      <td>0.233500</td>\n",
              "      <td>0.262589</td>\n",
              "      <td>0.915663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>0.252600</td>\n",
              "      <td>0.259162</td>\n",
              "      <td>0.963855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>830</td>\n",
              "      <td>0.230000</td>\n",
              "      <td>0.268866</td>\n",
              "      <td>0.951807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>0.248000</td>\n",
              "      <td>0.248947</td>\n",
              "      <td>0.975904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.222300</td>\n",
              "      <td>0.249734</td>\n",
              "      <td>0.951807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>0.218700</td>\n",
              "      <td>0.246749</td>\n",
              "      <td>0.963855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>870</td>\n",
              "      <td>0.221800</td>\n",
              "      <td>0.255618</td>\n",
              "      <td>0.951807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>0.201100</td>\n",
              "      <td>0.250929</td>\n",
              "      <td>0.927711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>890</td>\n",
              "      <td>0.233600</td>\n",
              "      <td>0.249563</td>\n",
              "      <td>0.963855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.203100</td>\n",
              "      <td>0.237113</td>\n",
              "      <td>0.951807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>910</td>\n",
              "      <td>0.231800</td>\n",
              "      <td>0.241083</td>\n",
              "      <td>0.951807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>0.220900</td>\n",
              "      <td>0.251141</td>\n",
              "      <td>0.939759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>0.234500</td>\n",
              "      <td>0.252008</td>\n",
              "      <td>0.951807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>0.232700</td>\n",
              "      <td>0.250897</td>\n",
              "      <td>0.927711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.231900</td>\n",
              "      <td>0.235179</td>\n",
              "      <td>0.927711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>0.196500</td>\n",
              "      <td>0.244783</td>\n",
              "      <td>0.927711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>970</td>\n",
              "      <td>0.253100</td>\n",
              "      <td>0.236551</td>\n",
              "      <td>1.012048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>0.185300</td>\n",
              "      <td>0.241430</td>\n",
              "      <td>0.951807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>990</td>\n",
              "      <td>0.222200</td>\n",
              "      <td>0.245805</td>\n",
              "      <td>0.915663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.214300</td>\n",
              "      <td>0.244332</td>\n",
              "      <td>0.903614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1010</td>\n",
              "      <td>0.233600</td>\n",
              "      <td>0.233103</td>\n",
              "      <td>0.951807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1020</td>\n",
              "      <td>0.192200</td>\n",
              "      <td>0.232113</td>\n",
              "      <td>0.963855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1030</td>\n",
              "      <td>0.198300</td>\n",
              "      <td>0.228262</td>\n",
              "      <td>0.963855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1040</td>\n",
              "      <td>0.188300</td>\n",
              "      <td>0.222550</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.198200</td>\n",
              "      <td>0.248938</td>\n",
              "      <td>0.975904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1060</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.242355</td>\n",
              "      <td>0.951807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1070</td>\n",
              "      <td>0.163300</td>\n",
              "      <td>0.248360</td>\n",
              "      <td>0.951807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1080</td>\n",
              "      <td>0.179900</td>\n",
              "      <td>0.233670</td>\n",
              "      <td>0.963855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1090</td>\n",
              "      <td>0.175400</td>\n",
              "      <td>0.225061</td>\n",
              "      <td>0.939759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.184300</td>\n",
              "      <td>0.232293</td>\n",
              "      <td>0.915663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1110</td>\n",
              "      <td>0.173100</td>\n",
              "      <td>0.244156</td>\n",
              "      <td>0.951807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1120</td>\n",
              "      <td>0.189000</td>\n",
              "      <td>0.233232</td>\n",
              "      <td>0.915663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1130</td>\n",
              "      <td>0.188600</td>\n",
              "      <td>0.232731</td>\n",
              "      <td>0.963855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1140</td>\n",
              "      <td>0.201900</td>\n",
              "      <td>0.235505</td>\n",
              "      <td>0.963855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.190900</td>\n",
              "      <td>0.239667</td>\n",
              "      <td>0.963855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1160</td>\n",
              "      <td>0.191300</td>\n",
              "      <td>0.229049</td>\n",
              "      <td>0.951807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1170</td>\n",
              "      <td>0.181500</td>\n",
              "      <td>0.238590</td>\n",
              "      <td>0.951807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1180</td>\n",
              "      <td>0.162100</td>\n",
              "      <td>0.240050</td>\n",
              "      <td>0.939759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1190</td>\n",
              "      <td>0.188800</td>\n",
              "      <td>0.224083</td>\n",
              "      <td>0.963855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.190800</td>\n",
              "      <td>0.233790</td>\n",
              "      <td>0.927711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1210</td>\n",
              "      <td>0.165000</td>\n",
              "      <td>0.223859</td>\n",
              "      <td>0.915663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1220</td>\n",
              "      <td>0.179300</td>\n",
              "      <td>0.213304</td>\n",
              "      <td>0.927711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1230</td>\n",
              "      <td>0.190800</td>\n",
              "      <td>0.213674</td>\n",
              "      <td>0.939759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1240</td>\n",
              "      <td>0.173700</td>\n",
              "      <td>0.227135</td>\n",
              "      <td>0.939759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.198600</td>\n",
              "      <td>0.214507</td>\n",
              "      <td>0.879518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1260</td>\n",
              "      <td>0.209800</td>\n",
              "      <td>0.207683</td>\n",
              "      <td>0.903614</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "d:\\Machine Learning\\INTERNSHIP\\Whisper-Malayalam-Finetuning\\.venv\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "d:\\Machine Learning\\INTERNSHIP\\Whisper-Malayalam-Finetuning\\.venv\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "d:\\Machine Learning\\INTERNSHIP\\Whisper-Malayalam-Finetuning\\.venv\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "d:\\Machine Learning\\INTERNSHIP\\Whisper-Malayalam-Finetuning\\.venv\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "d:\\Machine Learning\\INTERNSHIP\\Whisper-Malayalam-Finetuning\\.venv\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "d:\\Machine Learning\\INTERNSHIP\\Whisper-Malayalam-Finetuning\\.venv\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "d:\\Machine Learning\\INTERNSHIP\\Whisper-Malayalam-Finetuning\\.venv\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "d:\\Machine Learning\\INTERNSHIP\\Whisper-Malayalam-Finetuning\\.venv\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "d:\\Machine Learning\\INTERNSHIP\\Whisper-Malayalam-Finetuning\\.venv\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "d:\\Machine Learning\\INTERNSHIP\\Whisper-Malayalam-Finetuning\\.venv\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "d:\\Machine Learning\\INTERNSHIP\\Whisper-Malayalam-Finetuning\\.venv\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "d:\\Machine Learning\\INTERNSHIP\\Whisper-Malayalam-Finetuning\\.venv\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1265, training_loss=0.4542907324704257, metrics={'train_runtime': 4592.1208, 'train_samples_per_second': 2.202, 'train_steps_per_second': 0.275, 'total_flos': 3.06912374784e+18, 'train_loss': 0.4542907324704257, 'epoch': 5.0})"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Kie1Gbvj_07Q",
      "metadata": {
        "id": "Kie1Gbvj_07Q"
      },
      "outputs": [],
      "source": [
        "# Inference\n",
        "from peft import AutoPeftModel\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oU31USsi_040",
      "metadata": {
        "id": "oU31USsi_040"
      },
      "outputs": [],
      "source": [
        "test_model = AutoPeftModel.from_pretrained('checkpoints\\\\checkpoint-600')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8189669f",
      "metadata": {},
      "outputs": [],
      "source": [
        "test_model.to('cuda');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e6c9dfa",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "pipe = pipeline(\n",
        "    task='automatic-speech-recognition',\n",
        "    model=test_model,\n",
        "    tokenizer=processor.tokenizer,\n",
        "    feature_extractor=processor.feature_extractor\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14d3462c",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Machine Learning\\INTERNSHIP\\Whisper-Malayalam-Finetuning\\.venv\\Lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'text': 'ആലോ എന്നെ പര്രവാജ്ത്ത് ഞാന് കുണ്ട്ടിലുന്നുന്നും പുന്ന്നുപ്പ്പ്പ്പ്പ്പ്പുല്ല് എന്ന്നു സമുമമുനുനുനു ന്നുനുനുനുനുനുനുനുനുനുനുനുനുനുനുനുനുനുനുനുനുനുനുനുനുനുനുനുനുനുനുനുനുനുനനുനുനുനുനുന�ുന�ു�'}"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe('record_out.wav')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "681c6b59",
      "metadata": {},
      "outputs": [],
      "source": [
        "test_input = common_voice['test'][100]['input_features']\n",
        "test_labels = common_voice['test'][100]['labels']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a09b035",
      "metadata": {},
      "outputs": [],
      "source": [
        "test_input = torch.tensor(test_input).to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e2dc41c",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You have passed task=transcribe, but also have set `forced_decoder_ids` to [[1, None], [2, 50359]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=transcribe.\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "The following `model_kwargs` are not used by the model: ['langauge'] (note: typos in the generate arguments will also show up in this list)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m processor.decode(\u001b[43mtest_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtranscribe\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlangauge\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mml\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m])\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Machine Learning\\INTERNSHIP\\Whisper-Malayalam-Finetuning\\.venv\\Lib\\site-packages\\peft\\peft_model.py:823\u001b[39m, in \u001b[36mPeftModel.generate\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._enable_peft_forward_hooks(*args, **kwargs):\n\u001b[32m    822\u001b[39m     kwargs = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.special_peft_forward_args}\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_base_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Machine Learning\\INTERNSHIP\\Whisper-Malayalam-Finetuning\\.venv\\Lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:774\u001b[39m, in \u001b[36mWhisperGenerationMixin.generate\u001b[39m\u001b[34m(self, input_features, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, return_timestamps, task, language, is_multilingual, prompt_ids, prompt_condition_type, condition_on_prev_tokens, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, num_segment_frames, attention_mask, time_precision, time_precision_features, return_token_timestamps, return_segments, return_dict_in_generate, force_unique_generate_call, **kwargs)\u001b[39m\n\u001b[32m    765\u001b[39m             proc.set_begin_index(decoder_input_ids.shape[-\u001b[32m1\u001b[39m])\n\u001b[32m    767\u001b[39m \u001b[38;5;66;03m# 6.6 Run generate with fallback\u001b[39;00m\n\u001b[32m    768\u001b[39m (\n\u001b[32m    769\u001b[39m     seek_sequences,\n\u001b[32m    770\u001b[39m     seek_outputs,\n\u001b[32m    771\u001b[39m     should_skip,\n\u001b[32m    772\u001b[39m     do_condition_on_prev_tokens,\n\u001b[32m    773\u001b[39m     model_output_type,\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_with_fallback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    775\u001b[39m \u001b[43m    \u001b[49m\u001b[43msegment_input\u001b[49m\u001b[43m=\u001b[49m\u001b[43msegment_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    776\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcur_bsz\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcur_bsz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_idx_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_idx_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseek\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseek\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_segment_frames\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_segment_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    781\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_frames\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    782\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperatures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemperatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    783\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    784\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    785\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    786\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefix_allowed_tokens_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefix_allowed_tokens_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    787\u001b[39m \u001b[43m    \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_token_timestamps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_token_timestamps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdo_condition_on_prev_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdo_condition_on_prev_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_shortform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_shortform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[38;5;66;03m# 6.7 In every generated sequence, split by timestamp tokens and extract segments\u001b[39;00m\n\u001b[32m    797\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, seek_sequence \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(seek_sequences):\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Machine Learning\\INTERNSHIP\\Whisper-Malayalam-Finetuning\\.venv\\Lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:950\u001b[39m, in \u001b[36mWhisperGenerationMixin.generate_with_fallback\u001b[39m\u001b[34m(self, segment_input, decoder_input_ids, cur_bsz, batch_idx_map, seek, num_segment_frames, max_frames, temperatures, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, return_token_timestamps, do_condition_on_prev_tokens, is_shortform, batch_size, attention_mask, kwargs)\u001b[39m\n\u001b[32m    945\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m generate_kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mencoder_outputs\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    946\u001b[39m         generate_kwargs[\u001b[33m\"\u001b[39m\u001b[33mencoder_outputs\u001b[39m\u001b[33m\"\u001b[39m] = F.pad(\n\u001b[32m    947\u001b[39m             generate_kwargs[\u001b[33m\"\u001b[39m\u001b[33mencoder_outputs\u001b[39m\u001b[33m\"\u001b[39m], (\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, batch_size - cur_bsz), value=\u001b[32m0\u001b[39m\n\u001b[32m    948\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m950\u001b[39m seek_outputs = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m    \u001b[49m\u001b[43msegment_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefix_allowed_tokens_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefix_allowed_tokens_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m    \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    962\u001b[39m model_output_type = \u001b[38;5;28mtype\u001b[39m(seek_outputs)\n\u001b[32m    964\u001b[39m \u001b[38;5;66;03m# post-process sequence tokens and outputs to be in list form\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Machine Learning\\INTERNSHIP\\Whisper-Malayalam-Finetuning\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Machine Learning\\INTERNSHIP\\Whisper-Malayalam-Finetuning\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:2357\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2352\u001b[39m assistant_tokenizer = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33massistant_tokenizer\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# only used for assisted generation\u001b[39;00m\n\u001b[32m   2354\u001b[39m generation_config, model_kwargs = \u001b[38;5;28mself\u001b[39m._prepare_generation_config(\n\u001b[32m   2355\u001b[39m     generation_config, use_model_defaults, **kwargs\n\u001b[32m   2356\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m2357\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_model_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2358\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_assistant(assistant_model, tokenizer, assistant_tokenizer)\n\u001b[32m   2360\u001b[39m \u001b[38;5;66;03m# 2. Set generation parameters if not already defined\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Machine Learning\\INTERNSHIP\\Whisper-Malayalam-Finetuning\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:1599\u001b[39m, in \u001b[36mGenerationMixin._validate_model_kwargs\u001b[39m\u001b[34m(self, model_kwargs)\u001b[39m\n\u001b[32m   1596\u001b[39m         unused_model_args.append(key)\n\u001b[32m   1598\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m unused_model_args:\n\u001b[32m-> \u001b[39m\u001b[32m1599\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1600\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe following `model_kwargs` are not used by the model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munused_model_args\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (note: typos in the\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1601\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m generate arguments will also show up in this list)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1602\u001b[39m     )\n",
            "\u001b[31mValueError\u001b[39m: The following `model_kwargs` are not used by the model: ['langauge'] (note: typos in the generate arguments will also show up in this list)"
          ]
        }
      ],
      "source": [
        "processor.decode(test_model.generate(input_features=test_input, task='transcribe', langauge='ml')[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d87c8769",
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'shape'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtest_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Machine Learning\\INTERNSHIP\\Whisper-Malayalam-Finetuning\\.venv\\Lib\\site-packages\\peft\\peft_model.py:823\u001b[39m, in \u001b[36mPeftModel.generate\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._enable_peft_forward_hooks(*args, **kwargs):\n\u001b[32m    822\u001b[39m     kwargs = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.special_peft_forward_args}\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_base_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Machine Learning\\INTERNSHIP\\Whisper-Malayalam-Finetuning\\.venv\\Lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:584\u001b[39m, in \u001b[36mWhisperGenerationMixin.generate\u001b[39m\u001b[34m(self, input_features, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, return_timestamps, task, language, is_multilingual, prompt_ids, prompt_condition_type, condition_on_prev_tokens, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, num_segment_frames, attention_mask, time_precision, time_precision_features, return_token_timestamps, return_segments, return_dict_in_generate, force_unique_generate_call, **kwargs)\u001b[39m\n\u001b[32m    582\u001b[39m input_stride = \u001b[38;5;28mself\u001b[39m.model.encoder.conv1.stride[\u001b[32m0\u001b[39m] * \u001b[38;5;28mself\u001b[39m.model.encoder.conv2.stride[\u001b[32m0\u001b[39m]\n\u001b[32m    583\u001b[39m num_segment_frames = input_stride * \u001b[38;5;28mself\u001b[39m.config.max_source_positions\n\u001b[32m--> \u001b[39m\u001b[32m584\u001b[39m batch_size, total_input_frames = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retrieve_total_input_frames\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    585\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_stride\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_stride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    586\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    587\u001b[39m is_shortform = total_input_frames <= num_segment_frames\n\u001b[32m    589\u001b[39m \u001b[38;5;66;03m# 3. Make sure generation config is correctly set\u001b[39;00m\n\u001b[32m    590\u001b[39m \u001b[38;5;66;03m# Make sure the generation config is correctly set depending on whether timestamps are to be returned or not\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Machine Learning\\INTERNSHIP\\Whisper-Malayalam-Finetuning\\.venv\\Lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:1242\u001b[39m, in \u001b[36mWhisperGenerationMixin._retrieve_total_input_frames\u001b[39m\u001b[34m(input_features, input_stride, kwargs)\u001b[39m\n\u001b[32m   1239\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m   1240\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_retrieve_total_input_frames\u001b[39m(input_features, input_stride, kwargs):\n\u001b[32m   1241\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m input_features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minput_features\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m[\u001b[32m0\u001b[39m], input_features.shape[-\u001b[32m1\u001b[39m]\n\u001b[32m   1244\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoder_outputs\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[32m   1245\u001b[39m         encoder_outputs_shape = (\n\u001b[32m   1246\u001b[39m             kwargs[\u001b[33m\"\u001b[39m\u001b[33mencoder_outputs\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m].shape\n\u001b[32m   1247\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(kwargs[\u001b[33m\"\u001b[39m\u001b[33mencoder_outputs\u001b[39m\u001b[33m\"\u001b[39m], BaseModelOutput)\n\u001b[32m   1248\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m kwargs[\u001b[33m\"\u001b[39m\u001b[33mencoder_outputs\u001b[39m\u001b[33m\"\u001b[39m].shape\n\u001b[32m   1249\u001b[39m         )\n",
            "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'shape'"
          ]
        }
      ],
      "source": [
        "test_model.generate('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gDgOZepOjUhS",
      "metadata": {
        "id": "gDgOZepOjUhS"
      },
      "outputs": [],
      "source": [
        "def length_of_labels(batch):\n",
        "    return {\"label_len\" : len(batch['labels'])}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "A0W4iduw8S0l",
      "metadata": {
        "id": "A0W4iduw8S0l"
      },
      "outputs": [],
      "source": [
        "df = common_voice.map(length_of_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NnNK5g4-8lXB",
      "metadata": {
        "id": "NnNK5g4-8lXB"
      },
      "outputs": [],
      "source": [
        "train_label_length = df['train']['label_len']\n",
        "test_label_lenght = df['test']['label_len']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "J74KTRcm9RVX",
      "metadata": {
        "id": "J74KTRcm9RVX"
      },
      "outputs": [],
      "source": [
        "processor.tokenizer.pad([{'input_ids':df['train'][0]['labels']}])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pkuY34RJ87ru",
      "metadata": {
        "id": "pkuY34RJ87ru"
      },
      "outputs": [],
      "source": [
        "processor.tokenizer.pad()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
